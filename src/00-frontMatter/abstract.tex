%
% Halaman Abstract
%
% @author  Andreas Febrian
% @version 2.1.2
% @edit by Ichlasul Affan
%

\chapter*{ABSTRACT}
\singlespacing

\vspace*{0.2cm}

\noindent \begin{tabular}{l l p{11.0cm}}
	\ifx\blank\npmDua
		Name&: & \penulisSatu \\
		Study Program&: & \studyProgramSatu \\
	\else
		Writer 1 / Study Program&: & \penulisSatu~/ \studyProgramSatu\\
		Writer 2 / Study Program&: & \penulisDua~/ \studyProgramDua\\
	\fi
	\ifx\blank\npmTiga\else
		Writer 3 / Study Program&: & \penulisTiga~/ \studyProgramTiga\\
	\fi
	Title&: & \judulInggris \\
	Counselor&: & \pembimbingSatu \\
	\ifx\blank\pembimbingDua
	\else
		\ &\ & \pembimbingDua \\
	\fi
	\ifx\blank\pembimbingTiga
	\else
		\ &\ & \pembimbingTiga \\
	\fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent The increasing amount of digital text data requires humans to have mechanisms for retrieving text effectively and efficiently. One mechanism for text retrieval is text ranking. The goal of text ranking is to generate a list of texts sorted based on their relevance in responding to user query requests. In this study, the author uses Bidirectional Encoder Representations from Transformers (BERT) to build a text ranking model for the Indonesian language. The use of BERT improves the quality of text ranking compared to the baseline BM25 model. The improvement in the quality of text ranking can be seen from the values of the reciprocal rank (RR), recall (R), and normalized discounted cumulative gain (NDCG) metrics.



\vspace*{0.2cm}

\noindent Key words: \\ IndoBERT, text representation, information retrieval system, text scoring \\

\setstretch{1.4}
\newpage
